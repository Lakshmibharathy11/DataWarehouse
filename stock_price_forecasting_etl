# In Cloud Composer, add apache-airflow-providers-snowflake to PYPI Packages
from airflow import DAG
from airflow.models import Variable
from airflow.decorators import task
from airflow.providers.snowflake.hooks.snowflake import SnowflakeHook
from airflow.utils.dates import days_ago

from datetime import timedelta
from datetime import datetime
import snowflake.connector
import requests

import json

def return_snowflake_conn():

    # Initialize the SnowflakeHook
    hook = SnowflakeHook(snowflake_conn_id='snowflake_conn')

    # Execute the query and fetch results
    conn = hook.get_conn()
    return conn.cursor()

@task
def extract_stock(url):
    f = requests.get(url)
    data = f.json()
    return data

@task
def transform(data):
    records = []
    # for d in data["Weekly Time Series"]:
        # stock_info = data["Weekly Time Serie
    daily_data = data.get("Time Series (Daily)", {})
    for date, stock_info in daily_data.items():
        record = {
            "symbol": Variable.get("lab_symbol"),
            "date": date,
            "open": stock_info["1. open"],
            "close": stock_info["4. close"],
            "high": stock_info["2. high"],
            "low": stock_info["3. low"],
            "volume": stock_info["5. volume"]
        }
        records.append(record)

               
        if len(records) >= 180:
            break
         
    return records 

@task
def load_stock(cur, records, target_table):
    try:
        cur.execute("BEGIN;")
        cur.execute(f"CREATE TABLE IF NOT EXISTS {target_table} (symbol VARCHAR(10), date DATE, open FLOAT, close FLOAT, high FLOAT, low FLOAT, volume BIGINT, PRIMARY KEY (symbol, date));")
        cur.execute(f"DELETE FROM {target_table}")

        for r in records:
          symbol = r["symbol"]
          date = r["date"]
          open = r["open"]
          close = r["close"]
          high = r["high"]
          low = r["low"]
          volume = r["volume"]
          # Use parameterized query to avoid SQL injection and handle data types correctly
          cur.execute(f"INSERT INTO {target_table} (symbol, date, open, close, high, low, volume) VALUES (%s, %s, %s, %s, %s, %s, %s)", (symbol, date, open, close, high, low, volume))

        cur.execute("COMMIT;")
    except Exception as e:
        cur.execute("ROLLBACK;")
        print(e)
        raise e


with DAG (
    dag_id = 'Lab1_ETL',
    start_date = datetime(2025,2,21),
    catchup=False,
    tags=['ETL_stockprice'],
    schedule = '30 2 * * *'
) as dag:
    target_table_stock = "dev.raw.stock_price_lab"
    url = Variable.get("lab_stock_price_url")
    cur = return_snowflake_conn()

    data = extract_stock(url)
    stock_records = transform(data)
    load_stock(cur, stock_records, target_table_stock)











































































        

















    
    
    
    

    
    
    

    
    
    
